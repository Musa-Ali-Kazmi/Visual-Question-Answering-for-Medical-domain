{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0dd503d6d63aba67562eef8bfd8a908a2bfbbeb4aa49764dfef80fb35a855a9e7",
   "display_name": "Python 3.8.8 64-bit ('mlproject': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.io import imread, imsave\n",
    "import skimage\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],\n",
    "                                     std=[0.33165374, 0.33165374, 0.33165374])\n",
    "\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        lines = f.readlines()\n",
    "    txt_data = [line.strip() for line in lines]\n",
    "    return txt_data\n",
    "\n",
    "class CovidCTDataset(Dataset):\n",
    "    def __init__(self, root_dir, txt_COVID, txt_NonCOVID, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            txt_path (string): Path to the txt file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        File structure:\n",
    "        - root_dir\n",
    "            - CT_COVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "            - CT_NonCOVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.txt_path = [txt_COVID,txt_NonCOVID]\n",
    "        self.classes = ['CT_COVID', 'CT_NonCOVID']\n",
    "        self.num_cls = len(self.classes)\n",
    "        self.img_list = []\n",
    "        for c in range(self.num_cls):\n",
    "            cls_list = [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]\n",
    "            self.img_list += cls_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.img_list[idx][0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'img': image,\n",
    "                  'label': int(self.img_list[idx][1])}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 16\n",
    "\n",
    "trainset = CovidCTDataset(root_dir='/......../COVID-Downstream', #Update\n",
    "                            txt_COVID='Data-split/COVID/trainCT_COVID.txt',\n",
    "                            txt_NonCOVID='Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "                            transform= train_transformer)\n",
    "valset = CovidCTDataset(root_dir='/............/COVID-Downstream', #Update\n",
    "                            txt_COVID='Data-split/COVID/valCT_COVID.txt',\n",
    "                            txt_NonCOVID='Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "                            transform= val_transformer)\n",
    "testset = CovidCTDataset(root_dir='/.............../Barlow Twins/COVID-Downstream', #Update\n",
    "                            txt_COVID='Data-split/COVID/testCT_COVID.txt',\n",
    "                            txt_NonCOVID='Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "                            transform= val_transformer)\n",
    "print(trainset.__len__())\n",
    "print(valset.__len__())\n",
    "print(testset.__len__())\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batchsize, num_workers = 4, drop_last=True, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=batchsize, num_workers = 4, drop_last=True, shuffle=False)\n",
    "test_loader = DataLoader(testset, batch_size=batchsize, num_workers = 4, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_loader))\n",
    "\n",
    "img = a['img']\n",
    "skimage.io.imshow(img[0,1,:,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training process is defined here\n",
    "def train(epochs, model):\n",
    "    print('Starting training..')\n",
    "\n",
    "    for e in range(0, epochs):\n",
    "        print('='*16)\n",
    "        print(f'Starting epoch {e + 1}/{epochs}')\n",
    "        print('='*16)\n",
    "\n",
    "        train_loss = 0.\n",
    "        val_loss = 0.\n",
    "\n",
    "        model.train() # set model to training phase\n",
    "\n",
    "        for train_step, data in enumerate(train_loader):\n",
    "\n",
    "\n",
    "            images = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "          \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "\n",
    "            #print(outputs.shape)\n",
    "            loss = loss_fn(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            if train_step % batchsize == 0:\n",
    "                print('Evaluating at step', train_step)\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(e, train_step, \n",
    "                       len(train_loader),100.0 * train_step / len(train_loader), loss.item()/ batchsize))\n",
    "                                \n",
    "\n",
    "                accuracy = 0\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    \n",
    "\n",
    "                    model.eval() # set model to eval phase\n",
    "\n",
    "                    for val_step, data in enumerate(val_loader):\n",
    "\n",
    "                        images = data['img'].to(device)\n",
    "                        labels = data['label'].to(device)\n",
    "\n",
    "                        outputs = model(images)\n",
    "                        loss = loss_fn(outputs, labels.long())\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                        accuracy += sum((preds == labels))\n",
    "\n",
    "                    val_loss /= (val_step + 1)\n",
    "                    accuracy = accuracy/len(valset)\n",
    "\n",
    "                    print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "                    #show_preds()\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                if accuracy >= 0.98:\n",
    "                    print('Performance condition satisfied, stopping..')\n",
    "                    return model \n",
    "\n",
    "        train_loss /= (train_step + 1)\n",
    "\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "    print('Training complete..')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetModelSSL(nn.Module):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        Pass in parsed HyperOptArgumentParser to the model\n",
    "        :param hparams:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        pretrained_dict = torch.load(path)[\"state_dict\"]\n",
    "\n",
    "        state_dict = {}\n",
    "        for k, v in pretrained_dict.items():\n",
    "            if k.startswith(\"model.network.\"):\n",
    "                k = k.replace(\"model.network.\", \"\")\n",
    "                state_dict[k] = v\n",
    "\n",
    "        self.resnet = models.resnet50()\n",
    "        del self.resnet.fc\n",
    "\n",
    "        self.resnet.load_state_dict(state_dict)\n",
    "\n",
    "        self.resnet.fc =  nn.Sequential(\n",
    "            nn.Linear(2048, 2),\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.resnet(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_no = []\n",
    "acc = []\n",
    "F1 = []\n",
    "AUC = []\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    model = ResNetModelSSL('last.ckpt')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "\n",
    "    model = model.to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    loss_fn = loss_fn.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    model = train(epochs, model)\n",
    "\n",
    "    model = model.to('cpu')\n",
    "    model.eval() # set model to eval phase\n",
    "    y_true=[]\n",
    "    y_pred=[]\n",
    "    for test_step, data in enumerate(test_loader):\n",
    "\n",
    "        outputs = model(data['img'])\n",
    "\n",
    "        _, y = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.append(data['label'])\n",
    "        y_pred.append(y)\n",
    "\n",
    "\n",
    "    Y_true = torch.flatten(torch.stack(y_true))\n",
    "    Y_pred = torch.flatten(torch.stack(y_pred))\n",
    "\n",
    "\n",
    "    model_no.append(i)\n",
    "\n",
    "    F1.append(metrics.f1_score(Y_true,Y_pred))\n",
    "    AUC.append(roc_auc_score(Y_true, Y_pred))\n",
    "    acc.append(np.mean(Y_true.numpy()==Y_pred.numpy()))\n",
    "\n",
    "    print('='*16)\n",
    "    print('Training the Model number {}'.format(i+1))\n",
    "\n",
    "\n",
    "data = {'model': model_no,\n",
    "         'F1': F1,\n",
    "         'AUC': AUC,\n",
    "         'acc': acc}   \n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}